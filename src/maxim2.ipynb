{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything is in the last cell !\n",
    "\n",
    "current features:\n",
    "- engagement rate\n",
    "- average likes per post\n",
    "- average comments per post\n",
    "- not yet: virality rate, but would be cool (a draft of the formula is in the cell)\n",
    "\n",
    "\n",
    "also: i created a dictionary of company_name -> 2-d dataframe with time-series (sorted) data for that company\n",
    "called company_tables, index e.g. by company_tables['Nike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = '../data/skylab_instagram_datathon_dataset.csv'\n",
    "\n",
    "data = pd.read_csv(data_path, delimiter=';')  # Specify the delimiter (e.g., comma)\n",
    "\n",
    "data[\"period_end_date\"] = pd.to_datetime(data[\"period_end_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['period', 'period_end_date', 'compset_group', 'compset',\n",
      "       'business_entity_doing_business_as_name', 'legal_entity_name',\n",
      "       'domicile_country_name', 'ultimate_parent_legal_entity_name',\n",
      "       'primary_exchange_name', 'calculation_type', 'followers', 'pictures',\n",
      "       'videos', 'comments', 'likes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_cols = [\"followers\",\"pictures\",\"videos\",\"comments\",\"likes\"]\n",
    "funnylist = []\n",
    "\n",
    "for group_idx in data[\"compset_group\"].unique():\n",
    "    filtered_df = data[data[\"compset_group\"] == group_idx]\n",
    "    filtered_sum = filtered_df.isna().sum()\n",
    "    funnylist.append((group_idx,\n",
    "                      sum(filtered_sum[important_cols])/len(filtered_df)))\n",
    "\n",
    "funnydict = {idx:cumulative for idx,cumulative in funnylist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_yearly_means(df, col, category_column, category_value, period: str=\"yearly\"):\n",
    "    filtered_df = df[df[category_column] == category_value]\n",
    "    \n",
    "    # Convert the index to datetime if it's not already\n",
    "    if period == \"yearly\":\n",
    "        filtered_df[\"time\"] = pd.to_datetime(filtered_df[\"period_end_date\"]).dt.year\n",
    "    elif period == \"montly\":\n",
    "        filtered_df[\"time\"] = pd.to_datetime(filtered_df[\"period_end_date\"]).dt.month\n",
    "\n",
    "    yearly_means = filtered_df[col].groupby(filtered_df[\"time\"]).mean()\n",
    "    \n",
    "    return yearly_means\n",
    "\n",
    "\n",
    "metrics = [\"followers\", \"pictures\", \"likes\", \"videos\", \"comments\"]\n",
    "\n",
    "for col in metrics:\n",
    "    compset_groups = data[\"compset_group\"].unique()\n",
    "    num_columns = len(compset_groups)\n",
    "    fig, axes = plt.subplots(num_columns, 1, figsize=(10, 6*num_columns))\n",
    "    plt.title(col)\n",
    "    for i, cat in enumerate(compset_groups):\n",
    "        cat_means = calculate_yearly_means(df=data, col=\"followers\", category_column=\"compset\", category_value=cat)\n",
    "        cat_means.plot(ax=axes[i], title=cat)\n",
    "        axes[i].set_ylabel('Mean' + ' ' + col.capitalize())\n",
    "        axes[i].set_xlabel('Year')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by company name and period end date\n",
    "impute_test = data.sort_values(by=['business_entity_doing_business_as_name', 'period_end_date'])\n",
    "\n",
    "# Group the data by company name\n",
    "grouped = impute_test.groupby('business_entity_doing_business_as_name')\n",
    "\n",
    "# For each company, process the data to handle duplicates and compset variations\n",
    "company_tables = {}\n",
    "for name, group in grouped:\n",
    "    # Drop the company name column as it's redundant in individual company dataframes\n",
    "    group = group.drop(columns='business_entity_doing_business_as_name')\n",
    "    group.drop_duplicates()\n",
    "    \n",
    "    # Group by period_end_date and aggregate\n",
    "    group = group.groupby('period_end_date').agg({\n",
    "        'compset': lambda x: list(set(x)),  # Convert compset values to a set to remove duplicates, then to a list\n",
    "        'followers': 'mean',  # Assuming followers should be averaged\n",
    "        'pictures': 'sum',  # Summing up the pictures\n",
    "        'videos': 'sum',    # Summing up the videos\n",
    "        'comments': 'sum',  # Summing up the comments\n",
    "        'likes': 'sum'      # Summing up the likes\n",
    "    }).reset_index()\n",
    "\n",
    "    # Store the processed DataFrame back to the company_tables dictionary\n",
    "    company_tables[name] = group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    period_end_date                                            compset  \\\n",
      "0        2015-01-03  [US Softlines Analyst Interest List, Sportswea...   \n",
      "1        2015-01-10  [US Softlines Analyst Interest List, Sportswea...   \n",
      "2        2015-01-17  [US Softlines Analyst Interest List, Sportswea...   \n",
      "3        2015-01-24  [US Softlines Analyst Interest List, Sportswea...   \n",
      "4        2015-01-31  [US Softlines Analyst Interest List, Sportswea...   \n",
      "..              ...                                                ...   \n",
      "450      2023-08-19  [US Softlines Analyst Interest List, Sportswea...   \n",
      "451      2023-08-26  [US Softlines Analyst Interest List, Sportswea...   \n",
      "452      2023-09-02  [US Softlines Analyst Interest List, Sportswea...   \n",
      "453      2023-09-09  [US Softlines Analyst Interest List, Sportswea...   \n",
      "454      2023-09-16  [US Softlines Analyst Interest List, Sportswea...   \n",
      "\n",
      "       followers  pictures  videos  comments       likes  \n",
      "0     24471305.0     438.0     0.0  274617.0  34898691.0  \n",
      "1     25299746.0     465.0     3.0  321669.0  39738612.0  \n",
      "2     26143731.0     471.0     9.0  393432.0  43148382.0  \n",
      "3     26851899.0     447.0     9.0  383376.0  40263060.0  \n",
      "4     27483940.0     399.0     9.0  411510.0  36760893.0  \n",
      "..           ...       ...     ...       ...         ...  \n",
      "450  428373563.0     492.0   429.0  126495.0  27322110.0  \n",
      "451  428821658.0     543.0   378.0  133557.0  25539624.0  \n",
      "452  429403365.0     552.0   390.0  127002.0  26360820.0  \n",
      "453  429880713.0     531.0   426.0  125367.0  24868521.0  \n",
      "454  430176998.0     588.0   417.0  127542.0  27584172.0  \n",
      "\n",
      "[455 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Now each company's DataFrame is updated in the company_tables dictionary\n",
    "# For example, to view the data for 'Nike':\n",
    "nike_data = company_tables['Nike']\n",
    "print(nike_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  period_end_date  pictures       likes  comments   followers  \\\n",
      "0      2015-01-03     438.0  34898691.0  274617.0  24471305.0   \n",
      "1      2015-01-10     465.0  39738612.0  321669.0  25299746.0   \n",
      "2      2015-01-17     471.0  43148382.0  393432.0  26143731.0   \n",
      "3      2015-01-24     447.0  40263060.0  383376.0  26851899.0   \n",
      "4      2015-01-31     399.0  36760893.0  411510.0  27483940.0   \n",
      "\n",
      "   engagement_rate  average_likes_per_post  average_comments_per_post  \n",
      "0       143.732866            79677.194801                 626.978021  \n",
      "1       158.342621            84911.382668                 687.325454  \n",
      "2       166.547820            89892.275224                 819.648292  \n",
      "3       151.372668            88295.990579                 840.734998  \n",
      "4       135.251361            90100.007108                1008.600469  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = '../data/skylab_instagram_datathon_dataset.csv'\n",
    "\n",
    "data = pd.read_csv(data_path, delimiter=';')  # Specify the delimiter (e.g., comma)\n",
    "\n",
    "data[\"period_end_date\"] = pd.to_datetime(data[\"period_end_date\"])\n",
    "\n",
    "# Sort the data by company name and period end date\n",
    "impute_test = data.sort_values(by=['business_entity_doing_business_as_name', 'period_end_date'])\n",
    "\n",
    "# Group the data by company name\n",
    "grouped = impute_test.groupby('business_entity_doing_business_as_name')\n",
    "\n",
    "# For each company, process the data to handle duplicates and compset variations\n",
    "company_tables = {}\n",
    "for name, group in grouped:\n",
    "    # Drop the company name column as it's redundant in individual company dataframes\n",
    "    group = group.drop(columns='business_entity_doing_business_as_name')\n",
    "    group.drop_duplicates()\n",
    "    \n",
    "    # Group by period_end_date and aggregate\n",
    "    group = group.groupby('period_end_date').agg({\n",
    "        'compset': lambda x: list(set(x)),  # Convert compset values to a set to remove duplicates, then to a list\n",
    "        'followers': 'mean',  # Assuming followers should be averaged\n",
    "        'pictures': 'sum',  # Summing up the pictures\n",
    "        'videos': 'sum',    # Summing up the videos\n",
    "        'comments': 'sum',  # Summing up the comments\n",
    "        'likes': 'sum'      # Summing up the likes\n",
    "    }).reset_index()\n",
    "\n",
    "    # Store the processed DataFrame back to the company_tables dictionary\n",
    "    company_tables[name] = group\n",
    "\n",
    "\n",
    "# Iterate over each company in the company_tables\n",
    "for company, df in company_tables.items():\n",
    "    # Ensure the data is sorted by date - assuming 'period_end_date' is the weekly identifier\n",
    "    df = df.sort_values(by='period_end_date')\n",
    "\n",
    "    # Group by 'period_end_date' to handle data week by week\n",
    "    weekly_data = df.groupby('period_end_date').agg({\n",
    "        'likes': 'sum',\n",
    "        'comments': 'sum',\n",
    "        'followers': 'mean',  # Assuming 'followers' is stable across the week, we take the mean\n",
    "        'pictures': 'sum',    # Summing up the number of pictures\n",
    "        'videos': 'sum'       # Summing up the number of videos\n",
    "    }).reset_index()\n",
    "\n",
    "    # Calculate the average engagement per post for the baseline\n",
    "    weekly_data['average_engagement_per_post'] = (weekly_data['likes'] + weekly_data['comments']) / (weekly_data['pictures'] + weekly_data['videos'] + 0.001)\n",
    "\n",
    "    # Calculate the engagement rate for each week\n",
    "    weekly_data['engagement_rate'] = (weekly_data['likes'] + weekly_data['comments']) / weekly_data['followers'] * 100\n",
    "\n",
    "    # Calculate the like-to-comment ratio for each week\n",
    "    # I actually think this feature does not make sense\n",
    "    #weekly_data['like_to_comment_ratio'] = weekly_data['likes'] / (weekly_data['comments'] + 0.001)\n",
    "\n",
    "    # Calculate the average likes and comments per post for each week\n",
    "    weekly_data['average_likes_per_post'] = weekly_data['likes'] / (weekly_data['pictures'] + weekly_data['videos'] + 0.001)\n",
    "    weekly_data['average_comments_per_post'] = weekly_data['comments'] / (weekly_data['pictures'] + weekly_data['videos'] + 0.001)\n",
    "\n",
    "    # Calculate the virality rate for each week\n",
    "    # Virality rate = (engagement per post this week / average engagement per post baseline) * 100\n",
    "    # weekly_data['virality_rate'] = (weekly_data['average_engagement_per_post'] / weekly_data['average_engagement_per_post'].mean()) * 100\n",
    "\n",
    "    # Merge the calculated weekly metrics back to the original dataframe\n",
    "    df = pd.merge(df, weekly_data[['period_end_date', 'engagement_rate', 'average_likes_per_post', 'average_comments_per_post']], on='period_end_date', how='left')\n",
    "\n",
    "    # Update the company_tables dictionary with the modified DataFrame\n",
    "    company_tables[company] = df\n",
    "\n",
    "# Optionally, to check the results for a specific company, e.g., 'Nike'\n",
    "nike_data = company_tables['Nike']\n",
    "print(nike_data[['period_end_date', 'pictures', 'likes', 'comments', 'followers', 'engagement_rate', 'average_likes_per_post', 'average_comments_per_post']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
