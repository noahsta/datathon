{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = '../data/skylab_instagram_datathon_dataset.csv'\n",
    "\n",
    "data = pd.read_csv(data_path, delimiter=';')  # Specify the delimiter (e.g., comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704313\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['period', 'period_end_date', 'compset_group', 'compset',\n",
      "       'business_entity_doing_business_as_name', 'legal_entity_name',\n",
      "       'domicile_country_name', 'ultimate_parent_legal_entity_name',\n",
      "       'primary_exchange_name', 'calculation_type', 'followers', 'pictures',\n",
      "       'videos', 'comments', 'likes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Luxury & Premium & Mainstream' 'Restaurants' 'Beverages'\n",
      " 'Apparel Retail' 'Food Products' 'Sporting Goods'\n",
      " 'Sportswear & Athleisure' 'Beauty & Boutique' 'Building Products'\n",
      " 'Petcare' 'Toys & Collectibles' 'Mattress' 'Fitness & Exercise'\n",
      " 'Food Retail' 'Discount Retailers ' 'Outdoor Gear'\n",
      " 'Dermatology and Orthodontics' 'Entertainment' 'Home Appliances'\n",
      " 'Study (All Brands)']\n"
     ]
    }
   ],
   "source": [
    "unique_compset_groups = data['compset_group'].unique()\n",
    "print(unique_compset_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Soft Luxury' 'Luxury & Premium & Mainstream'\n",
      " 'US Softlines Analyst Interest List'\n",
      " 'Global Luxury Analysts Interest List' 'Coffee' 'Restaurants' 'Beverages'\n",
      " 'Sports drinks' 'Energy drinks' 'Fast Fashion'\n",
      " 'Omnichannel Apparel Retail' 'Apparel Retail' 'US Department Store'\n",
      " 'Latam Apparel Retail' 'Food Products' 'Snack Bars' 'Pasta Sauce'\n",
      " 'Ecommerce Apparel Retail' 'Ecommerce Mainstream Apparel Retail'\n",
      " 'Sporting Goods' 'Casual Dining' 'Hard Luxury' 'Sportswear & Athleisure'\n",
      " 'Athleisure' 'Footwear' 'Beauty & Boutique' 'Building Products'\n",
      " 'Sportswear' 'Petcare' 'Premium Brands' 'QSR' 'Alcohol'\n",
      " 'Toys & Collectibles' 'Mattress' 'Fitness & Exercise' 'US Discount Store'\n",
      " 'Ecommerce Luxury Apparel Retail' 'Plant-Based Meat' 'Food Retail'\n",
      " 'Discount Retailers ' 'Mid-Range Watch & Jewelry' 'Outdoor Gear'\n",
      " 'Plant-Based Dairy' 'Mainstream Brands' 'Dermatology and Orthodontics'\n",
      " 'Dermatology' 'Entertainment' 'Workout Gear' 'Yoghurt' 'Home Appliances'\n",
      " 'Soda' 'Fast Casual' 'Study (All Brands)' 'Orthodontics']\n"
     ]
    }
   ],
   "source": [
    "unique_compset = data['compset'].unique()\n",
    "print(unique_compset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Dictionary to store mapping from compset_group to list of unique compsets\n",
    "from_str = 'ultimate_parent_legal_entity_name'\n",
    "to_str = 'legal_entity_name'\n",
    "print_path = 'ultimate_entity_to_subentities.json'\n",
    "map_from_to = {}\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = '../data/skylab_instagram_datathon_dataset.csv'\n",
    "\n",
    "# Open the CSV file\n",
    "with open(csv_file_path, newline='') as csvfile:\n",
    "    # Create a CSV reader object\n",
    "    reader = csv.DictReader(csvfile, delimiter=';')\n",
    "    \n",
    "    # Iterate over each row in the CSV file\n",
    "    for row in reader:\n",
    "        # Extract compset_group and compset values from the current row\n",
    "        compset_group = row[from_str]\n",
    "        compset = row[to_str]\n",
    "        \n",
    "        # Check if compset_group is already in the map\n",
    "        if compset_group in map_from_to:\n",
    "            # If compset_group is already in the map, append compset to its list\n",
    "            map_from_to[compset_group].append(compset)\n",
    "        else:\n",
    "            # If compset_group is not in the map, create a new list with compset and add it to the map\n",
    "            map_from_to[compset_group] = [compset]\n",
    "\n",
    "# Convert the compset lists to sets to remove duplicates, then back to lists\n",
    "for compset_group, compsets in map_from_to.items():\n",
    "    map_from_to[compset_group] = list(set(compsets))\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "compset_group_json = json.dumps(map_from_to, indent=4)\n",
    "\n",
    "# Path to write the output JSON file\n",
    "output_file_path = f'../out/{print_path}'\n",
    "\n",
    "# Write the JSON string to a file\n",
    "with open(output_file_path, 'w') as outfile:\n",
    "    outfile.write(compset_group_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
